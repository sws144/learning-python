{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 101 Pandas Exercises\n",
    "https://www.machinelearningplus.com/python/101-pandas-exercises-python/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n",
      "{'system': {'commit': None, 'python': '3.7.6.final.0', 'python-bits': 64, 'OS': 'Windows', 'OS-release': '10', 'machine': 'AMD64', 'processor': 'Intel64 Family 6 Model 158 Stepping 9, GenuineIntel', 'byteorder': 'little', 'LC_ALL': 'None', 'LANG': 'None', 'LOCALE': 'None.None'}, 'dependencies': {'pandas': '1.0.1', 'numpy': '1.18.1', 'pytz': '2019.3', 'dateutil': '2.8.1', 'pip': '20.0.2', 'setuptools': '45.2.0.post20200210', 'Cython': '0.29.15', 'pytest': '5.3.5', 'hypothesis': '5.5.4', 'sphinx': '2.4.0', 'blosc': None, 'feather': None, 'xlsxwriter': '1.2.7', 'lxml.etree': '4.5.0', 'html5lib': '1.0.1', 'pymysql': None, 'psycopg2': None, 'jinja2': '2.11.1', 'IPython': '7.12.0', 'pandas_datareader': None, 'bs4': '4.8.2', 'bottleneck': '1.3.2', 'fastparquet': None, 'gcsfs': None, 'matplotlib': '3.1.3', 'numexpr': '2.7.1', 'odfpy': None, 'openpyxl': '3.0.3', 'pandas_gbq': None, 'pyarrow': None, 'pytables': None, 'pyxlsb': None, 's3fs': None, 'scipy': '1.4.1', 'sqlalchemy': '1.3.13', 'tables': '3.6.1', 'tabulate': None, 'xarray': None, 'xlrd': '1.2.0', 'xlwt': '1.3.0', 'numba': '0.48.0'}}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "print(pd.show_versions(as_json=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_mylist = pd.Series(mylist)\n",
    "series_myarr = pd.Series(myarr)\n",
    "series_mydict  = pd.Series(mydict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the index of a series into a column of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "ser = pd.Series(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "zip(*iterables) --> zip object\n",
       "\n",
       "Return a zip object whose .__next__() method returns a tuple where\n",
       "the i-th element comes from the i-th iterable argument.  The .__next__()\n",
       "method continues until the shortest iterable in the argument sequence\n",
       "is exhausted and then it raises StopIteration.\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  0\n",
      "0     a  0\n",
      "1     b  1\n",
      "2     c  2\n",
      "3     e  3\n",
      "4     d  4\n"
     ]
    }
   ],
   "source": [
    "df_ser = pd.DataFrame(ser).reset_index()\n",
    "print(df_ser.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "dict() -> new empty dictionary\n",
       "dict(mapping) -> new dictionary initialized from a mapping object's\n",
       "    (key, value) pairs\n",
       "dict(iterable) -> new dictionary initialized as if via:\n",
       "    d = {}\n",
       "    for k, v in iterable:\n",
       "        d[k] = v\n",
       "dict(**kwargs) -> new dictionary initialized with the name=value pairs\n",
       "    in the keyword argument list.  For example:  dict(one=1, two=2)\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     OrderedDict, defaultdict, Counter, _EnumDict, Bunch, Config, Struct, ColorSchemeTable, StgDict, _CharSizesCache, ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to combine many series to form a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser2 = pd.Series(np.arange(26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ser1n2 = pd.DataFrame({'co1' : ser1, 'col2' : ser2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCollection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCollection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ExtensionDtype'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
       "\n",
       "Data structure also contains labeled axes (rows and columns).\n",
       "Arithmetic operations align on both row and column labels. Can be\n",
       "thought of as a dict-like container for Series objects. The primary\n",
       "pandas data structure.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
       "    Dict can contain Series, arrays, constants, or list-like objects.\n",
       "\n",
       "    .. versionchanged:: 0.23.0\n",
       "       If data is a dict, column order follows insertion-order for\n",
       "       Python 3.6 and later.\n",
       "\n",
       "    .. versionchanged:: 0.25.0\n",
       "       If data is a list of dicts, column order follows insertion-order\n",
       "       for Python 3.6 and later.\n",
       "\n",
       "index : Index or array-like\n",
       "    Index to use for resulting frame. Will default to RangeIndex if\n",
       "    no indexing information part of input data and no index provided.\n",
       "columns : Index or array-like\n",
       "    Column labels to use for resulting frame. Will default to\n",
       "    RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n",
       "dtype : dtype, default None\n",
       "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
       "copy : bool, default False\n",
       "    Copy data from inputs. Only affects DataFrame / 2d ndarray input.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
       "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
       "read_csv\n",
       "read_table\n",
       "read_clipboard\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Constructing DataFrame from a dictionary.\n",
       "\n",
       ">>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
       ">>> df = pd.DataFrame(data=d)\n",
       ">>> df\n",
       "   col1  col2\n",
       "0     1     3\n",
       "1     2     4\n",
       "\n",
       "Notice that the inferred dtype is int64.\n",
       "\n",
       ">>> df.dtypes\n",
       "col1    int64\n",
       "col2    int64\n",
       "dtype: object\n",
       "\n",
       "To enforce a single dtype:\n",
       "\n",
       ">>> df = pd.DataFrame(data=d, dtype=np.int8)\n",
       ">>> df.dtypes\n",
       "col1    int8\n",
       "col2    int8\n",
       "dtype: object\n",
       "\n",
       "Constructing DataFrame from numpy ndarray:\n",
       "\n",
       ">>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
       "...                    columns=['a', 'b', 'c'])\n",
       ">>> df2\n",
       "   a  b  c\n",
       "0  1  2  3\n",
       "1  4  5  6\n",
       "2  7  8  9\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\sw\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     SubclassedDataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mobjs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataFrame'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Series'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataFrame'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Series'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mjoin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverify_integrity\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataFrame'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Series'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Concatenate pandas objects along a particular axis with optional set logic\n",
       "along the other axes.\n",
       "\n",
       "Can also add a layer of hierarchical indexing on the concatenation axis,\n",
       "which may be useful if the labels are the same (or overlapping) on\n",
       "the passed axis number.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "objs : a sequence or mapping of Series or DataFrame objects\n",
       "    If a dict is passed, the sorted keys will be used as the `keys`\n",
       "    argument, unless it is passed, in which case the values will be\n",
       "    selected (see below). Any None objects will be dropped silently unless\n",
       "    they are all None in which case a ValueError will be raised.\n",
       "axis : {0/'index', 1/'columns'}, default 0\n",
       "    The axis to concatenate along.\n",
       "join : {'inner', 'outer'}, default 'outer'\n",
       "    How to handle indexes on other axis (or axes).\n",
       "ignore_index : bool, default False\n",
       "    If True, do not use the index values along the concatenation axis. The\n",
       "    resulting axis will be labeled 0, ..., n - 1. This is useful if you are\n",
       "    concatenating objects where the concatenation axis does not have\n",
       "    meaningful indexing information. Note the index values on the other\n",
       "    axes are still respected in the join.\n",
       "keys : sequence, default None\n",
       "    If multiple levels passed, should contain tuples. Construct\n",
       "    hierarchical index using the passed keys as the outermost level.\n",
       "levels : list of sequences, default None\n",
       "    Specific levels (unique values) to use for constructing a\n",
       "    MultiIndex. Otherwise they will be inferred from the keys.\n",
       "names : list, default None\n",
       "    Names for the levels in the resulting hierarchical index.\n",
       "verify_integrity : bool, default False\n",
       "    Check whether the new concatenated axis contains duplicates. This can\n",
       "    be very expensive relative to the actual data concatenation.\n",
       "sort : bool, default False\n",
       "    Sort non-concatenation axis if it is not already aligned when `join`\n",
       "    is 'outer'.\n",
       "    This has no effect when ``join='inner'``, which already preserves\n",
       "    the order of the non-concatenation axis.\n",
       "\n",
       "    .. versionadded:: 0.23.0\n",
       "    .. versionchanged:: 1.0.0\n",
       "\n",
       "       Changed to not sort by default.\n",
       "\n",
       "copy : bool, default True\n",
       "    If False, do not copy data unnecessarily.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "object, type of objs\n",
       "    When concatenating all ``Series`` along the index (axis=0), a\n",
       "    ``Series`` is returned. When ``objs`` contains at least one\n",
       "    ``DataFrame``, a ``DataFrame`` is returned. When concatenating along\n",
       "    the columns (axis=1), a ``DataFrame`` is returned.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "Series.append : Concatenate Series.\n",
       "DataFrame.append : Concatenate DataFrames.\n",
       "DataFrame.join : Join DataFrames using indexes.\n",
       "DataFrame.merge : Merge DataFrames by indexes or columns.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The keys, levels, and names arguments are all optional.\n",
       "\n",
       "A walkthrough of how this method fits in with other tools for combining\n",
       "pandas objects can be found `here\n",
       "<https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html>`__.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Combine two ``Series``.\n",
       "\n",
       ">>> s1 = pd.Series(['a', 'b'])\n",
       ">>> s2 = pd.Series(['c', 'd'])\n",
       ">>> pd.concat([s1, s2])\n",
       "0    a\n",
       "1    b\n",
       "0    c\n",
       "1    d\n",
       "dtype: object\n",
       "\n",
       "Clear the existing index and reset it in the result\n",
       "by setting the ``ignore_index`` option to ``True``.\n",
       "\n",
       ">>> pd.concat([s1, s2], ignore_index=True)\n",
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    d\n",
       "dtype: object\n",
       "\n",
       "Add a hierarchical index at the outermost level of\n",
       "the data with the ``keys`` option.\n",
       "\n",
       ">>> pd.concat([s1, s2], keys=['s1', 's2'])\n",
       "s1  0    a\n",
       "    1    b\n",
       "s2  0    c\n",
       "    1    d\n",
       "dtype: object\n",
       "\n",
       "Label the index keys you create with the ``names`` option.\n",
       "\n",
       ">>> pd.concat([s1, s2], keys=['s1', 's2'],\n",
       "...           names=['Series name', 'Row ID'])\n",
       "Series name  Row ID\n",
       "s1           0         a\n",
       "             1         b\n",
       "s2           0         c\n",
       "             1         d\n",
       "dtype: object\n",
       "\n",
       "Combine two ``DataFrame`` objects with identical columns.\n",
       "\n",
       ">>> df1 = pd.DataFrame([['a', 1], ['b', 2]],\n",
       "...                    columns=['letter', 'number'])\n",
       ">>> df1\n",
       "  letter  number\n",
       "0      a       1\n",
       "1      b       2\n",
       ">>> df2 = pd.DataFrame([['c', 3], ['d', 4]],\n",
       "...                    columns=['letter', 'number'])\n",
       ">>> df2\n",
       "  letter  number\n",
       "0      c       3\n",
       "1      d       4\n",
       ">>> pd.concat([df1, df2])\n",
       "  letter  number\n",
       "0      a       1\n",
       "1      b       2\n",
       "0      c       3\n",
       "1      d       4\n",
       "\n",
       "Combine ``DataFrame`` objects with overlapping columns\n",
       "and return everything. Columns outside the intersection will\n",
       "be filled with ``NaN`` values.\n",
       "\n",
       ">>> df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n",
       "...                    columns=['letter', 'number', 'animal'])\n",
       ">>> df3\n",
       "  letter  number animal\n",
       "0      c       3    cat\n",
       "1      d       4    dog\n",
       ">>> pd.concat([df1, df3], sort=False)\n",
       "  letter  number animal\n",
       "0      a       1    NaN\n",
       "1      b       2    NaN\n",
       "0      c       3    cat\n",
       "1      d       4    dog\n",
       "\n",
       "Combine ``DataFrame`` objects with overlapping columns\n",
       "and return only those that are shared by passing ``inner`` to\n",
       "the ``join`` keyword argument.\n",
       "\n",
       ">>> pd.concat([df1, df3], join=\"inner\")\n",
       "  letter  number\n",
       "0      a       1\n",
       "1      b       2\n",
       "0      c       3\n",
       "1      d       4\n",
       "\n",
       "Combine ``DataFrame`` objects horizontally along the x axis by\n",
       "passing in ``axis=1``.\n",
       "\n",
       ">>> df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n",
       "...                    columns=['animal', 'name'])\n",
       ">>> pd.concat([df1, df4], axis=1)\n",
       "  letter  number  animal    name\n",
       "0      a       1    bird   polly\n",
       "1      b       2  monkey  george\n",
       "\n",
       "Prevent the result from including duplicate index values with the\n",
       "``verify_integrity`` option.\n",
       "\n",
       ">>> df5 = pd.DataFrame([1], index=['a'])\n",
       ">>> df5\n",
       "   0\n",
       "a  1\n",
       ">>> df6 = pd.DataFrame([2], index=['a'])\n",
       ">>> df6\n",
       "   0\n",
       "a  2\n",
       ">>> pd.concat([df5, df6], verify_integrity=True)\n",
       "Traceback (most recent call last):\n",
       "    ...\n",
       "ValueError: Indexes have overlapping values: ['a']\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\sw\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?pd.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ser1, ser2], axis = 1) #1 is col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## How to assign name to the series’ index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.name = 'alphabets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    e\n",
       "4    d\n",
       "Name: alphabets, dtype: object"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get the items of series A not present in series B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1[~ser1.isin(ser2)] # select ser1 by index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get the items not common to both series A and series B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncom1 = ser1[~ser1.isin(ser2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncom2 = ser2[~ser2.isin(ser1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "2    6\n",
       "3    7\n",
       "4    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncom1.append(uncom2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  How to get the minimum, 25th percentile, median, 75th, and max of a numeric series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.normal(10, 5, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "normal(loc=0.0, scale=1.0, size=None)\n",
       "\n",
       "Draw random samples from a normal (Gaussian) distribution.\n",
       "\n",
       "The probability density function of the normal distribution, first\n",
       "derived by De Moivre and 200 years later by both Gauss and Laplace\n",
       "independently [2]_, is often called the bell curve because of\n",
       "its characteristic shape (see the example below).\n",
       "\n",
       "The normal distributions occurs often in nature.  For example, it\n",
       "describes the commonly occurring distribution of samples influenced\n",
       "by a large number of tiny, random disturbances, each with its own\n",
       "unique distribution [2]_.\n",
       "\n",
       ".. note::\n",
       "    New code should use the ``normal`` method of a ``default_rng()``\n",
       "    instance instead; see `random-quick-start`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "loc : float or array_like of floats\n",
       "    Mean (\"centre\") of the distribution.\n",
       "scale : float or array_like of floats\n",
       "    Standard deviation (spread or \"width\") of the distribution. Must be\n",
       "    non-negative.\n",
       "size : int or tuple of ints, optional\n",
       "    Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
       "    ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
       "    a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
       "    Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "out : ndarray or scalar\n",
       "    Drawn samples from the parameterized normal distribution.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "scipy.stats.norm : probability density function, distribution or\n",
       "    cumulative density function, etc.\n",
       "Generator.normal: which should be used for new code.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The probability density for the Gaussian distribution is\n",
       "\n",
       ".. math:: p(x) = \\frac{1}{\\sqrt{ 2 \\pi \\sigma^2 }}\n",
       "                 e^{ - \\frac{ (x - \\mu)^2 } {2 \\sigma^2} },\n",
       "\n",
       "where :math:`\\mu` is the mean and :math:`\\sigma` the standard\n",
       "deviation. The square of the standard deviation, :math:`\\sigma^2`,\n",
       "is called the variance.\n",
       "\n",
       "The function has its peak at the mean, and its \"spread\" increases with\n",
       "the standard deviation (the function reaches 0.607 times its maximum at\n",
       ":math:`x + \\sigma` and :math:`x - \\sigma` [2]_).  This implies that\n",
       "normal is more likely to return samples lying close to the mean, rather\n",
       "than those far away.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] Wikipedia, \"Normal distribution\",\n",
       "       https://en.wikipedia.org/wiki/Normal_distribution\n",
       ".. [2] P. R. Peebles Jr., \"Central Limit Theorem\" in \"Probability,\n",
       "       Random Variables and Random Signal Principles\", 4th ed., 2001,\n",
       "       pp. 51, 51, 125.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Draw samples from the distribution:\n",
       "\n",
       ">>> mu, sigma = 0, 0.1 # mean and standard deviation\n",
       ">>> s = np.random.normal(mu, sigma, 1000)\n",
       "\n",
       "Verify the mean and the variance:\n",
       "\n",
       ">>> abs(mu - np.mean(s))\n",
       "0.0  # may vary\n",
       "\n",
       ">>> abs(sigma - np.std(s, ddof=1))\n",
       "0.1  # may vary\n",
       "\n",
       "Display the histogram of the samples, along with\n",
       "the probability density function:\n",
       "\n",
       ">>> import matplotlib.pyplot as plt\n",
       ">>> count, bins, ignored = plt.hist(s, 30, density=True)\n",
       ">>> plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
       "...                np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
       "...          linewidth=2, color='r')\n",
       ">>> plt.show()\n",
       "\n",
       "Two-by-four array of samples from N(3, 6.25):\n",
       "\n",
       ">>> np.random.normal(3, 2.5, size=(2, 4))\n",
       "array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random\n",
       "       [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?np.random.normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.12674695, 10.73481416, 12.11738053, 14.35468142, 18.45165552])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(ser, q=[0,25,50,75,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get frequency counts of unique items of a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Take elements from an array along an axis.\n",
       "\n",
       "When axis is not None, this function does the same thing as \"fancy\"\n",
       "indexing (indexing arrays using arrays); however, it can be easier to use\n",
       "if you need elements along a given axis. A call such as\n",
       "``np.take(arr, indices, axis=3)`` is equivalent to\n",
       "``arr[:,:,:,indices,...]``.\n",
       "\n",
       "Explained without fancy indexing, this is equivalent to the following use\n",
       "of `ndindex`, which sets each of ``ii``, ``jj``, and ``kk`` to a tuple of\n",
       "indices::\n",
       "\n",
       "    Ni, Nk = a.shape[:axis], a.shape[axis+1:]\n",
       "    Nj = indices.shape\n",
       "    for ii in ndindex(Ni):\n",
       "        for jj in ndindex(Nj):\n",
       "            for kk in ndindex(Nk):\n",
       "                out[ii + jj + kk] = a[ii + (indices[jj],) + kk]\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "a : array_like (Ni..., M, Nk...)\n",
       "    The source array.\n",
       "indices : array_like (Nj...)\n",
       "    The indices of the values to extract.\n",
       "\n",
       "    .. versionadded:: 1.8.0\n",
       "\n",
       "    Also allow scalars for indices.\n",
       "axis : int, optional\n",
       "    The axis over which to select values. By default, the flattened\n",
       "    input array is used.\n",
       "out : ndarray, optional (Ni..., Nj..., Nk...)\n",
       "    If provided, the result will be placed in this array. It should\n",
       "    be of the appropriate shape and dtype. Note that `out` is always\n",
       "    buffered if `mode='raise'`; use other modes for better performance.\n",
       "mode : {'raise', 'wrap', 'clip'}, optional\n",
       "    Specifies how out-of-bounds indices will behave.\n",
       "\n",
       "    * 'raise' -- raise an error (default)\n",
       "    * 'wrap' -- wrap around\n",
       "    * 'clip' -- clip to the range\n",
       "\n",
       "    'clip' mode means that all indices that are too large are replaced\n",
       "    by the index that addresses the last element along that axis. Note\n",
       "    that this disables indexing with negative numbers.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "out : ndarray (Ni..., Nj..., Nk...)\n",
       "    The returned array has the same type as `a`.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "compress : Take elements using a boolean mask\n",
       "ndarray.take : equivalent method\n",
       "take_along_axis : Take elements by matching the array and the index arrays\n",
       "\n",
       "Notes\n",
       "-----\n",
       "\n",
       "By eliminating the inner loop in the description above, and using `s_` to\n",
       "build simple slice objects, `take` can be expressed  in terms of applying\n",
       "fancy indexing to each 1-d slice::\n",
       "\n",
       "    Ni, Nk = a.shape[:axis], a.shape[axis+1:]\n",
       "    for ii in ndindex(Ni):\n",
       "        for kk in ndindex(Nj):\n",
       "            out[ii + s_[...,] + kk] = a[ii + s_[:,] + kk][indices]\n",
       "\n",
       "For this reason, it is equivalent to (but faster than) the following use\n",
       "of `apply_along_axis`::\n",
       "\n",
       "    out = np.apply_along_axis(lambda a_1d: a_1d[indices], axis, a)\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> a = [4, 3, 5, 7, 6, 8]\n",
       ">>> indices = [0, 1, 4]\n",
       ">>> np.take(a, indices)\n",
       "array([4, 3, 6])\n",
       "\n",
       "In this example if `a` is an ndarray, \"fancy\" indexing can be used.\n",
       "\n",
       ">>> a = np.array(a)\n",
       ">>> a[indices]\n",
       "array([4, 3, 6])\n",
       "\n",
       "If `indices` is not one dimensional, the output also has these dimensions.\n",
       "\n",
       ">>> np.take(a, [[0, 1], [2, 3]])\n",
       "array([[4, 3],\n",
       "       [5, 7]])\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\sw\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?np.take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Built-in mutable sequence.\n",
       "\n",
       "If no argument is given, the constructor creates a new empty list.\n",
       "The argument must be an iterable if specified.\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     _HashedSeq, StackSummary, SList, _ImmutableLineList, FormattedText, NodeList, _ExplodedList, Stack, _Accumulator, _ymd, ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e    6\n",
       "f    5\n",
       "h    5\n",
       "c    4\n",
       "g    4\n",
       "d    3\n",
       "b    2\n",
       "a    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to keep only top 2 most frequent values as it is and replace everything else as ‘Other’?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "RandomState(seed=None)\n",
       "\n",
       "Container for the slow Mersenne Twister pseudo-random number generator.\n",
       "Consider using a different BitGenerator with the Generator container\n",
       "instead.\n",
       "\n",
       "`RandomState` and `Generator` expose a number of methods for generating\n",
       "random numbers drawn from a variety of probability distributions. In\n",
       "addition to the distribution-specific arguments, each method takes a\n",
       "keyword argument `size` that defaults to ``None``. If `size` is ``None``,\n",
       "then a single value is generated and returned. If `size` is an integer,\n",
       "then a 1-D array filled with generated values is returned. If `size` is a\n",
       "tuple, then an array with that shape is filled and returned.\n",
       "\n",
       "**Compatibility Guarantee**\n",
       "\n",
       "A fixed bit generator using a fixed seed and a fixed series of calls to\n",
       "'RandomState' methods using the same parameters will always produce the\n",
       "same results up to roundoff error except when the values were incorrect.\n",
       "`RandomState` is effectively frozen and will only receive updates that\n",
       "are required by changes in the the internals of Numpy. More substantial\n",
       "changes, including algorithmic improvements, are reserved for\n",
       "`Generator`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "seed : {None, int, array_like, BitGenerator}, optional\n",
       "    Random seed used to initialize the pseudo-random number generator or\n",
       "    an instantized BitGenerator.  If an integer or array, used as a seed for\n",
       "    the MT19937 BitGenerator. Values can be any integer between 0 and\n",
       "    2**32 - 1 inclusive, an array (or other sequence) of such integers,\n",
       "    or ``None`` (the default).  If `seed` is ``None``, then the `MT19937`\n",
       "    BitGenerator is initialized by reading data from ``/dev/urandom``\n",
       "    (or the Windows analogue) if available or seed from the clock\n",
       "    otherwise.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The Python stdlib module \"random\" also contains a Mersenne Twister\n",
       "pseudo-random number generator with a number of methods that are similar\n",
       "to the ones available in `RandomState`. `RandomState`, besides being\n",
       "NumPy-aware, has the advantage that it provides a much larger number\n",
       "of probability distributions to choose from.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "Generator\n",
       "MT19937\n",
       "numpy.random.BitGenerator\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\sw\\anaconda3\\lib\\site-packages\\numpy\\random\\mtrand.cp37-win_amd64.pyd\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?np.random.RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "randint(low, high=None, size=None, dtype='l')\n",
       "\n",
       "Return random integers from `low` (inclusive) to `high` (exclusive).\n",
       "\n",
       "Return random integers from the \"discrete uniform\" distribution of\n",
       "the specified dtype in the \"half-open\" interval [`low`, `high`). If\n",
       "`high` is None (the default), then results are from [0, `low`).\n",
       "\n",
       ".. note::\n",
       "    New code should use the ``integers`` method of a ``default_rng()``\n",
       "    instance instead; see `random-quick-start`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "low : int or array-like of ints\n",
       "    Lowest (signed) integers to be drawn from the distribution (unless\n",
       "    ``high=None``, in which case this parameter is one above the\n",
       "    *highest* such integer).\n",
       "high : int or array-like of ints, optional\n",
       "    If provided, one above the largest (signed) integer to be drawn\n",
       "    from the distribution (see above for behavior if ``high=None``).\n",
       "    If array-like, must contain integer values\n",
       "size : int or tuple of ints, optional\n",
       "    Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
       "    ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
       "    single value is returned.\n",
       "dtype : dtype, optional\n",
       "    Desired dtype of the result. All dtypes are determined by their\n",
       "    name, i.e., 'int64', 'int', etc, so byteorder is not available\n",
       "    and a specific precision may have different C types depending\n",
       "    on the platform. The default value is `np.int_`.\n",
       "\n",
       "    .. versionadded:: 1.11.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "out : int or ndarray of ints\n",
       "    `size`-shaped array of random integers from the appropriate\n",
       "    distribution, or a single such random int if `size` not provided.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "random_integers : similar to `randint`, only for the closed\n",
       "    interval [`low`, `high`], and 1 is the lowest value if `high` is\n",
       "    omitted.\n",
       "Generator.integers: which should be used for new code.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> np.random.randint(2, size=10)\n",
       "array([1, 0, 0, 0, 1, 1, 0, 0, 1, 0]) # random\n",
       ">>> np.random.randint(1, size=10)\n",
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
       "\n",
       "Generate a 2 x 4 array of ints between 0 and 4, inclusive:\n",
       "\n",
       ">>> np.random.randint(5, size=(2, 4))\n",
       "array([[4, 0, 2, 1], # random\n",
       "       [3, 2, 2, 0]])\n",
       "\n",
       "Generate a 1 x 3 array with 3 different upper bounds\n",
       "\n",
       ">>> np.random.randint(1, [3, 5, 10])\n",
       "array([2, 2, 9]) # random\n",
       "\n",
       "Generate a 1 by 3 array with 3 different lower bounds\n",
       "\n",
       ">>> np.random.randint([1, 5, 7], 10)\n",
       "array([9, 8, 7]) # random\n",
       "\n",
       "Generate a 2 by 4 array using broadcasting with dtype of uint8\n",
       "\n",
       ">>> np.random.randint([1, 3, 5, 7], [[10], [20]], dtype=np.uint8)\n",
       "array([[ 8,  6,  9,  7], # random\n",
       "       [ 1, 16,  9, 12]], dtype=uint8)\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?np.random.randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "valcnts = ser.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Return a sorted copy of an array.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "a : array_like\n",
       "    Array to be sorted.\n",
       "axis : int or None, optional\n",
       "    Axis along which to sort. If None, the array is flattened before\n",
       "    sorting. The default is -1, which sorts along the last axis.\n",
       "kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional\n",
       "    Sorting algorithm. The default is 'quicksort'. Note that both 'stable'\n",
       "    and 'mergesort' use timsort or radix sort under the covers and, in general,\n",
       "    the actual implementation will vary with data type. The 'mergesort' option\n",
       "    is retained for backwards compatibility.\n",
       "\n",
       "    .. versionchanged:: 1.15.0.\n",
       "       The 'stable' option was added.\n",
       "\n",
       "order : str or list of str, optional\n",
       "    When `a` is an array with fields defined, this argument specifies\n",
       "    which fields to compare first, second, etc.  A single field can\n",
       "    be specified as a string, and not all fields need be specified,\n",
       "    but unspecified fields will still be used, in the order in which\n",
       "    they come up in the dtype, to break ties.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "sorted_array : ndarray\n",
       "    Array of the same type and shape as `a`.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "ndarray.sort : Method to sort an array in-place.\n",
       "argsort : Indirect sort.\n",
       "lexsort : Indirect stable sort on multiple keys.\n",
       "searchsorted : Find elements in a sorted array.\n",
       "partition : Partial sort.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The various sorting algorithms are characterized by their average speed,\n",
       "worst case performance, work space size, and whether they are stable. A\n",
       "stable sort keeps items with the same key in the same relative\n",
       "order. The four algorithms implemented in NumPy have the following\n",
       "properties:\n",
       "\n",
       "=========== ======= ============= ============ ========\n",
       "   kind      speed   worst case    work space   stable\n",
       "=========== ======= ============= ============ ========\n",
       "'quicksort'    1     O(n^2)            0          no\n",
       "'heapsort'     3     O(n*log(n))       0          no\n",
       "'mergesort'    2     O(n*log(n))      ~n/2        yes\n",
       "'timsort'      2     O(n*log(n))      ~n/2        yes\n",
       "=========== ======= ============= ============ ========\n",
       "\n",
       ".. note:: The datatype determines which of 'mergesort' or 'timsort'\n",
       "   is actually used, even if 'mergesort' is specified. User selection\n",
       "   at a finer scale is not currently available.\n",
       "\n",
       "All the sort algorithms make temporary copies of the data when\n",
       "sorting along any but the last axis.  Consequently, sorting along\n",
       "the last axis is faster and uses less space than sorting along\n",
       "any other axis.\n",
       "\n",
       "The sort order for complex numbers is lexicographic. If both the real\n",
       "and imaginary parts are non-nan then the order is determined by the\n",
       "real parts except when they are equal, in which case the order is\n",
       "determined by the imaginary parts.\n",
       "\n",
       "Previous to numpy 1.4.0 sorting real and complex arrays containing nan\n",
       "values led to undefined behaviour. In numpy versions >= 1.4.0 nan\n",
       "values are sorted to the end. The extended sort order is:\n",
       "\n",
       "  * Real: [R, nan]\n",
       "  * Complex: [R + Rj, R + nanj, nan + Rj, nan + nanj]\n",
       "\n",
       "where R is a non-nan real value. Complex values with the same nan\n",
       "placements are sorted according to the non-nan part if it exists.\n",
       "Non-nan values are sorted as before.\n",
       "\n",
       ".. versionadded:: 1.12.0\n",
       "\n",
       "quicksort has been changed to `introsort <https://en.wikipedia.org/wiki/Introsort>`_.\n",
       "When sorting does not make enough progress it switches to\n",
       "`heapsort <https://en.wikipedia.org/wiki/Heapsort>`_.\n",
       "This implementation makes quicksort O(n*log(n)) in the worst case.\n",
       "\n",
       "'stable' automatically chooses the best stable sorting algorithm\n",
       "for the data type being sorted.\n",
       "It, along with 'mergesort' is currently mapped to\n",
       "`timsort <https://en.wikipedia.org/wiki/Timsort>`_\n",
       "or `radix sort <https://en.wikipedia.org/wiki/Radix_sort>`_\n",
       "depending on the data type.\n",
       "API forward compatibility currently limits the\n",
       "ability to select the implementation and it is hardwired for the different\n",
       "data types.\n",
       "\n",
       ".. versionadded:: 1.17.0\n",
       "\n",
       "Timsort is added for better performance on already or nearly\n",
       "sorted data. On random data timsort is almost identical to\n",
       "mergesort. It is now used for stable sort while quicksort is still the\n",
       "default sort if none is chosen. For timsort details, refer to\n",
       "`CPython listsort.txt <https://github.com/python/cpython/blob/3.7/Objects/listsort.txt>`_.\n",
       "'mergesort' and 'stable' are mapped to radix sort for integer data types. Radix sort is an\n",
       "O(n) sort instead of O(n log n).\n",
       "\n",
       ".. versionchanged:: 1.17.0\n",
       "\n",
       "NaT now sorts to the end of arrays for consistency with NaN.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> a = np.array([[1,4],[3,1]])\n",
       ">>> np.sort(a)                # sort along the last axis\n",
       "array([[1, 4],\n",
       "       [1, 3]])\n",
       ">>> np.sort(a, axis=None)     # sort the flattened array\n",
       "array([1, 1, 3, 4])\n",
       ">>> np.sort(a, axis=0)        # sort along the first axis\n",
       "array([[1, 1],\n",
       "       [3, 4]])\n",
       "\n",
       "Use the `order` keyword to specify a field to use when sorting a\n",
       "structured array:\n",
       "\n",
       ">>> dtype = [('name', 'S10'), ('height', float), ('age', int)]\n",
       ">>> values = [('Arthur', 1.8, 41), ('Lancelot', 1.9, 38),\n",
       "...           ('Galahad', 1.7, 38)]\n",
       ">>> a = np.array(values, dtype=dtype)       # create a structured array\n",
       ">>> np.sort(a, order='height')                        # doctest: +SKIP\n",
       "array([('Galahad', 1.7, 38), ('Arthur', 1.8, 41),\n",
       "       ('Lancelot', 1.8999999999999999, 38)],\n",
       "      dtype=[('name', '|S10'), ('height', '<f8'), ('age', '<i4')])\n",
       "\n",
       "Sort by age, then height if ages are equal:\n",
       "\n",
       ">>> np.sort(a, order=['age', 'height'])               # doctest: +SKIP\n",
       "array([('Galahad', 1.7, 38), ('Lancelot', 1.8999999999999999, 38),\n",
       "       ('Arthur', 1.8, 41)],\n",
       "      dtype=[('name', '|S10'), ('height', '<f8'), ('age', '<i4')])\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\sw\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?np.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    6\n",
      "4    2\n",
      "3    2\n",
      "2    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ser.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser[~ser.isin(ser.value_counts().index[:2])] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Other\n",
      "1         1\n",
      "2         4\n",
      "3     Other\n",
      "4     Other\n",
      "      ...  \n",
      "7         1\n",
      "8         1\n",
      "9         1\n",
      "10        1\n",
      "11    Other\n",
      "Length: 12, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to bin a numeric series to 10 groups of equal size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.random(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.094362\n",
      "1     0.578348\n",
      "2     0.427363\n",
      "3     0.556279\n",
      "4     0.637167\n",
      "        ...   \n",
      "15    0.845463\n",
      "16    0.672129\n",
      "17    0.736056\n",
      "18    0.821126\n",
      "19    0.876157\n",
      "Length: 20, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2nd\n",
       "1    6th\n",
       "2    3rd\n",
       "3    5th\n",
       "4    7th\n",
       "dtype: category\n",
       "Categories (10, object): [1st < 2nd < 3rd < 4th ... 7th < 8th < 9th < 10th]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(ser, [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "       labels=['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1st\n",
       "1     3rd\n",
       "2     2nd\n",
       "3     2nd\n",
       "4     3rd\n",
       "     ... \n",
       "15    4th\n",
       "16    3rd\n",
       "17    3rd\n",
       "18    4th\n",
       "19    4th\n",
       "Length: 20, dtype: category\n",
       "Categories (4, object): [1st < 2nd < 3rd < 4th]"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(ser, [0,0.25,0.5,0.75,1],\n",
    "       labels=['1st', '2nd', '3rd', '4th'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to convert a numpy array to a dataframe of given shape? (L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 3, 3, 9, 6, 4, 7, 3, 9, 2, 3, 3, 9, 1, 4, 1, 8, 2, 2, 5, 9, 5,\n",
       "       1, 9, 9, 9, 7, 7, 9, 4, 2, 4, 8, 7, 3])"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ser.values.reshape(7,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4\n",
      "0  8  3  3  9  6\n",
      "1  4  7  3  9  2\n",
      "2  3  3  9  1  4\n",
      "3  1  8  2  2  5\n",
      "4  9  5  1  9  9\n",
      "5  9  7  7  9  4\n",
      "6  2  4  8  7  3\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to find the positions of numbers that are multiples of 3 from a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    9\n",
      "1    6\n",
      "2    1\n",
      "3    1\n",
      "4    7\n",
      "5    6\n",
      "6    1\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [5]], dtype=int64)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(ser.values % 3 == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to extract items at given positions from a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "pos = [0, 4, 8, 14, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a\n",
       "4     e\n",
       "8     i\n",
       "14    o\n",
       "20    u\n",
       "dtype: object"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a\n",
       "4     e\n",
       "8     i\n",
       "14    o\n",
       "20    u\n",
       "dtype: object"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.take(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to stack two series vertically and horizontally ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1\n",
      "0  0  a\n",
      "1  1  b\n",
      "2  2  c\n",
      "3  3  d\n",
      "4  4  e\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([ser1,ser2], axis = 1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    d\n",
      "4    e\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([ser1,ser2], axis = 0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get the positions of items of series A in another series B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 0, 8]"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pd.Index(ser1).get_loc(i) for i in ser2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 0, 8]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pd.Index(ser1).get_loc(i) for i in ser2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to compute the mean squared error on a truth and predicted series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10)) + np.random.random(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean((truth - pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36320992283293446\n"
     ]
    }
   ],
   "source": [
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to convert the first character of each element in a series to uppercase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     How\n",
       "1      To\n",
       "2    Kick\n",
       "3    Ass?\n",
       "dtype: object"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.map(lambda x: x[0].upper() + x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     How\n",
       "1      To\n",
       "2    Kick\n",
       "3    Ass?\n",
       "dtype: object"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.map(lambda x: x.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     How\n",
       "1      To\n",
       "2    Kick\n",
       "3    Ass?\n",
       "dtype: object"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([i.title() for i in ser])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to calculate the number of characters in each word in a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    2\n",
       "2    4\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to compute difference of differences between consequtive numbers of a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2 = ser.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff  = ser.subtract(ser2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, nan, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0]"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.diff().diff().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to convert a series of date-strings to a timeseries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-01 00:00:00\n",
       "1   2011-02-02 00:00:00\n",
       "2   2012-03-03 00:00:00\n",
       "3   2013-04-04 00:00:00\n",
       "4   2014-05-05 00:00:00\n",
       "5   2015-06-06 12:20:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-01 00:00:00\n",
       "1   2011-02-02 00:00:00\n",
       "2   2012-03-03 00:00:00\n",
       "3   2013-04-04 00:00:00\n",
       "4   2014-05-05 00:00:00\n",
       "5   2015-06-06 12:20:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "ser.map(lambda x: parse(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get the day of month, week number, day of year and day of week from a series of date strings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "ser_ts = ser.map(lambda x: parse(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  [1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "print(\"Date: \", ser_ts.dt.day.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  [53, 5, 9, 14, 19, 23]\n"
     ]
    }
   ],
   "source": [
    "print(\"Date: \", ser_ts.dt.week.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  [2010, 2011, 2012, 2013, 2014, 2015]\n"
     ]
    }
   ],
   "source": [
    "print(\"Date: \", ser_ts.dt.year.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  [4, 2, 5, 3, 0, 5]\n"
     ]
    }
   ],
   "source": [
    "print(\"Date: \", ser_ts.dt.weekday.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to convert year-month string to dates corresponding to the 4th day of the month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_ts = ser.map(lambda x: parse('04 ' + x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2010-01-04\n",
      "1   2011-02-04\n",
      "2   2012-03-04\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(ser_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to filter words that contain at least 2 vowels from a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Apple\n",
       "1    Orange\n",
       "4     Money\n",
       "dtype: object"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "mask = ser.map(lambda x: sum([Counter(x.lower()).get(i, 0) for i in list('aeiou')]) >= 2)\n",
    "ser[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "mask_two = ser.map(lambda x: sum([Counter(x.lower()).get(i,0) for i in list('aeiou')]) >=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Apple\n",
       "1    Orange\n",
       "4     Money\n",
       "dtype: object"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser[mask_two]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to filter valid emails from a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     []\n",
       "1    [rameses@egypt.com]\n",
       "2            [matt@t.co]\n",
       "3    [narendra@modi.com]\n",
       "dtype: object"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.str.findall(pattern, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    rameses@egypt.com\n",
       "2            matt@t.co\n",
       "3    narendra@modi.com\n",
       "dtype: object"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = emails.map(lambda x: bool(re.match(pattern, x)))\n",
    "emails[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rameses@egypt.com', 'matt@t.co', 'narendra@modi.com']"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in [re.findall(pattern, email) for email in emails] if len(x) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get the mean of a series grouped by another series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
      "['banana', 'apple', 'banana', 'apple', 'apple', 'apple', 'banana', 'banana', 'carrot', 'carrot']\n"
     ]
    }
   ],
   "source": [
    "fruits = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "print(weights.tolist())\n",
    "print(fruits.tolist())\n",
    "#> [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "#> ['banana', 'carrot', 'apple', 'carrot', 'carrot', 'apple', 'banana', 'carrot', 'apple', 'carrot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apple     4.25\n",
       "banana    4.75\n",
       "carrot    9.50\n",
       "dtype: float64"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.groupby(fruits).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to compute the euclidean distance between two series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.16590212458495"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((p-q)**2)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to find all the local maxima (or peaks) in a numeric series? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = np.diff(np.sign(np.diff(ser)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_locs = np.where(dd == -2)[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 7], dtype=int64)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprepend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mno\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mno\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Calculate the n-th discrete difference along the given axis.\n",
       "\n",
       "The first difference is given by ``out[i] = a[i+1] - a[i]`` along\n",
       "the given axis, higher differences are calculated by using `diff`\n",
       "recursively.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "a : array_like\n",
       "    Input array\n",
       "n : int, optional\n",
       "    The number of times values are differenced. If zero, the input\n",
       "    is returned as-is.\n",
       "axis : int, optional\n",
       "    The axis along which the difference is taken, default is the\n",
       "    last axis.\n",
       "prepend, append : array_like, optional\n",
       "    Values to prepend or append to `a` along axis prior to\n",
       "    performing the difference.  Scalar values are expanded to\n",
       "    arrays with length 1 in the direction of axis and the shape\n",
       "    of the input array in along all other axes.  Otherwise the\n",
       "    dimension and shape must match `a` except along axis.\n",
       "\n",
       "    .. versionadded:: 1.16.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "diff : ndarray\n",
       "    The n-th differences. The shape of the output is the same as `a`\n",
       "    except along `axis` where the dimension is smaller by `n`. The\n",
       "    type of the output is the same as the type of the difference\n",
       "    between any two elements of `a`. This is the same as the type of\n",
       "    `a` in most cases. A notable exception is `datetime64`, which\n",
       "    results in a `timedelta64` output array.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "gradient, ediff1d, cumsum\n",
       "\n",
       "Notes\n",
       "-----\n",
       "Type is preserved for boolean arrays, so the result will contain\n",
       "`False` when consecutive elements are the same and `True` when they\n",
       "differ.\n",
       "\n",
       "For unsigned integer arrays, the results will also be unsigned. This\n",
       "should not be surprising, as the result is consistent with\n",
       "calculating the difference directly:\n",
       "\n",
       ">>> u8_arr = np.array([1, 0], dtype=np.uint8)\n",
       ">>> np.diff(u8_arr)\n",
       "array([255], dtype=uint8)\n",
       ">>> u8_arr[1,...] - u8_arr[0,...]\n",
       "255\n",
       "\n",
       "If this is not desirable, then the array should be cast to a larger\n",
       "integer type first:\n",
       "\n",
       ">>> i16_arr = u8_arr.astype(np.int16)\n",
       ">>> np.diff(i16_arr)\n",
       "array([-1], dtype=int16)\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> x = np.array([1, 2, 4, 7, 0])\n",
       ">>> np.diff(x)\n",
       "array([ 1,  2,  3, -7])\n",
       ">>> np.diff(x, n=2)\n",
       "array([  1,   1, -10])\n",
       "\n",
       ">>> x = np.array([[1, 3, 6, 10], [0, 5, 6, 8]])\n",
       ">>> np.diff(x)\n",
       "array([[2, 3, 4],\n",
       "       [5, 1, 2]])\n",
       ">>> np.diff(x, axis=0)\n",
       "array([[-1,  2,  0, -2]])\n",
       "\n",
       ">>> x = np.arange('1066-10-13', '1066-10-16', dtype=np.datetime64)\n",
       ">>> np.diff(x)\n",
       "array([1, 1], dtype='timedelta64[D]')\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\sw\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?np.diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to replace missing spaces in a string with the least frequent character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_str = 'dbc deb abed gade'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(list('dbc deb abed gade'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.value_counts(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d    4\n",
      "     3\n",
      "e    3\n",
      "b    3\n",
      "a    2\n",
      "c    1\n",
      "g    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_freq = freq.dropna().index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dbcgdebgabedggade'"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(ser.replace(\" \", least_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create a TimeSeries starting ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "One-dimensional ndarray with axis labels (including time series).\n",
       "\n",
       "Labels need not be unique but must be a hashable type. The object\n",
       "supports both integer- and label-based indexing and provides a host of\n",
       "methods for performing operations involving the index. Statistical\n",
       "methods from ndarray have been overridden to automatically exclude\n",
       "missing data (currently represented as NaN).\n",
       "\n",
       "Operations between Series (+, -, /, *, **) align values based on their\n",
       "associated index values-- they need not be the same length. The result\n",
       "index will be the sorted union of the two indexes.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data : array-like, Iterable, dict, or scalar value\n",
       "    Contains data stored in Series.\n",
       "\n",
       "    .. versionchanged:: 0.23.0\n",
       "       If data is a dict, argument order is maintained for Python 3.6\n",
       "       and later.\n",
       "\n",
       "index : array-like or Index (1d)\n",
       "    Values must be hashable and have the same length as `data`.\n",
       "    Non-unique index values are allowed. Will default to\n",
       "    RangeIndex (0, 1, 2, ..., n) if not provided. If both a dict and index\n",
       "    sequence are used, the index will override the keys found in the\n",
       "    dict.\n",
       "dtype : str, numpy.dtype, or ExtensionDtype, optional\n",
       "    Data type for the output Series. If not specified, this will be\n",
       "    inferred from `data`.\n",
       "    See the :ref:`user guide <basics.dtypes>` for more usages.\n",
       "name : str, optional\n",
       "    The name to give to the Series.\n",
       "copy : bool, default False\n",
       "    Copy input data.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\sw\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     SubclassedSeries\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.randint(1,10,10),pd.date_range('2000-01-01',periods=10, freq='W-SAT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01    4\n",
      "2000-01-08    4\n",
      "2000-01-15    9\n",
      "2000-01-22    3\n",
      "2000-01-29    7\n",
      "2000-02-05    6\n",
      "2000-02-12    7\n",
      "2000-02-19    1\n",
      "2000-02-26    8\n",
      "2000-03-04    9\n",
      "Freq: W-SAT, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to fill an intermittent time series so all missing dates show up with values of previous non-missing date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01     1.0\n",
      "2000-01-03    10.0\n",
      "2000-01-06     3.0\n",
      "2000-01-08     NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01     1.0\n",
       "2000-01-02    10.0\n",
       "2000-01-03    10.0\n",
       "2000-01-04     3.0\n",
       "2000-01-05     3.0\n",
       "2000-01-06     3.0\n",
       "2000-01-07     3.0\n",
       "2000-01-08     3.0\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.resample('D').bfill().ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to compute the autocorrelations of a numeric series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     -0.711169\n",
      "1      2.808925\n",
      "2     -2.183277\n",
      "3      9.032198\n",
      "4      5.367368\n",
      "        ...    \n",
      "15    10.874170\n",
      "16     7.351218\n",
      "17    14.846081\n",
      "18     4.708078\n",
      "19    10.565294\n",
      "Length: 20, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelations = [ser.autocorr(i).round(2) for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, -0.18, -0.13, 0.3, 0.16, -0.34, 0.06, -0.03, 0.08, -0.43, 0.31]\n"
     ]
    }
   ],
   "source": [
    "print(autocorrelations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lag having highest correlation:  9\n"
     ]
    }
   ],
   "source": [
    "print('Lag having highest correlation: ', np.argmax(np.abs(autocorrelations[1:]))+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to import only every nth row from a csv file to create a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\n",
    "df2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in df:\n",
    "    df2 = df2.append(chunk.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        TextFileReader\n",
       "\u001b[1;31mString form:\u001b[0m <pandas.io.parsers.TextFileReader object at 0x000001756FDE0548>\n",
       "\u001b[1;31mFile:\u001b[0m        c:\\users\\sw\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\n",
       "\u001b[1;31mDocstring:\u001b[0m   Passed dialect overrides any of the related parser options\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>b</th>\n",
       "      <th>chas</th>\n",
       "      <th>crim</th>\n",
       "      <th>dis</th>\n",
       "      <th>...</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>rad</th>\n",
       "      <th>rm</th>\n",
       "      <th>tax</th>\n",
       "      <th>zn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>...</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.575</td>\n",
       "      <td>296.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>45.7</td>\n",
       "      <td>395.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08873</td>\n",
       "      <td>6.8147</td>\n",
       "      <td>...</td>\n",
       "      <td>16.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.963</td>\n",
       "      <td>243.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>79.9</td>\n",
       "      <td>394.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14866</td>\n",
       "      <td>2.7778</td>\n",
       "      <td>...</td>\n",
       "      <td>20.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.727</td>\n",
       "      <td>384.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>97.3</td>\n",
       "      <td>372.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.65660</td>\n",
       "      <td>1.6180</td>\n",
       "      <td>...</td>\n",
       "      <td>14.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.122</td>\n",
       "      <td>403.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>13.9</td>\n",
       "      <td>384.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01778</td>\n",
       "      <td>7.6534</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.135</td>\n",
       "      <td>402.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age       b  chas     crim     dis  ...  ptratio  rad     rm    tax  \\\n",
       "0    65.2  396.90   0.0  0.00632  4.0900  ...     15.3  1.0  6.575  296.0   \n",
       "50   45.7  395.56   0.0  0.08873  6.8147  ...     16.8  4.0  5.963  243.0   \n",
       "100  79.9  394.76   0.0  0.14866  2.7778  ...     20.9  5.0  6.727  384.0   \n",
       "150  97.3  372.80   0.0  1.65660  1.6180  ...     14.7  5.0  6.122  403.0   \n",
       "200  13.9  384.30   0.0  0.01778  7.6534  ...     17.0  3.0  7.135  402.0   \n",
       "\n",
       "       zn  \n",
       "0    18.0  \n",
       "50   21.0  \n",
       "100   0.0  \n",
       "150   0.0  \n",
       "200  95.0  \n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\n",
    "df2 = pd.concat([pd.DataFrame(chunk.iloc[0,:]).transpose() for chunk in df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>...</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>...</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.08873</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.439</td>\n",
       "      <td>...</td>\n",
       "      <td>243.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>395.56</td>\n",
       "      <td>13.45</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.14866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>...</td>\n",
       "      <td>384.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>394.76</td>\n",
       "      <td>9.42</td>\n",
       "      <td>27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1.65660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>...</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>372.80</td>\n",
       "      <td>14.10</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.01778</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>...</td>\n",
       "      <td>402.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>384.30</td>\n",
       "      <td>4.45</td>\n",
       "      <td>32.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim    zn  indus  chas    nox  ...    tax  ptratio       b  lstat  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98   \n",
       "50   0.08873  21.0   5.64   0.0  0.439  ...  243.0     16.8  395.56  13.45   \n",
       "100  0.14866   0.0   8.56   0.0  0.520  ...  384.0     20.9  394.76   9.42   \n",
       "150  1.65660   0.0  19.58   0.0  0.871  ...  403.0     14.7  372.80  14.10   \n",
       "200  0.01778  95.0   1.47   0.0  0.403  ...  402.0     17.0  384.30   4.45   \n",
       "\n",
       "     medv  \n",
       "0    24.0  \n",
       "50   19.7  \n",
       "100  27.5  \n",
       "150  21.5  \n",
       "200  32.9  \n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to change column values when importing csv to a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', \n",
    "                 converters={'medv': lambda x: 'High' if float(x) > 25 else 'Low'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
       "       'ptratio', 'b', 'lstat', 'medv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['medv'] = np.where(df['lstat']>5,\"lstathigh\", \"lstatlow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create a dataframe with rows as strides from a given series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = pd.Series(range(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_strides(a,stride_len=5, window_len = 5):\n",
    "    n_strides = ((a.size-window_len)//stride_len) -1\n",
    "    return np.array([a[s:(s+window_len)] for s in np.arange(0,a.size,stride_len)[:n_strides]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3]\n",
      " [2 3 4 5]\n",
      " [4 5 6 7]\n",
      " [6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "ans = gen_strides(L,stride_len=2,window_len=4)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(L.size - 5)//2 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "arange([start,] stop[, step,], dtype=None)\n",
       "\n",
       "Return evenly spaced values within a given interval.\n",
       "\n",
       "Values are generated within the half-open interval ``[start, stop)``\n",
       "(in other words, the interval including `start` but excluding `stop`).\n",
       "For integer arguments the function is equivalent to the Python built-in\n",
       "`range` function, but returns an ndarray rather than a list.\n",
       "\n",
       "When using a non-integer step, such as 0.1, the results will often not\n",
       "be consistent.  It is better to use `numpy.linspace` for these cases.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "start : number, optional\n",
       "    Start of interval.  The interval includes this value.  The default\n",
       "    start value is 0.\n",
       "stop : number\n",
       "    End of interval.  The interval does not include this value, except\n",
       "    in some cases where `step` is not an integer and floating point\n",
       "    round-off affects the length of `out`.\n",
       "step : number, optional\n",
       "    Spacing between values.  For any output `out`, this is the distance\n",
       "    between two adjacent values, ``out[i+1] - out[i]``.  The default\n",
       "    step size is 1.  If `step` is specified as a position argument,\n",
       "    `start` must also be given.\n",
       "dtype : dtype\n",
       "    The type of the output array.  If `dtype` is not given, infer the data\n",
       "    type from the other input arguments.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "arange : ndarray\n",
       "    Array of evenly spaced values.\n",
       "\n",
       "    For floating point arguments, the length of the result is\n",
       "    ``ceil((stop - start)/step)``.  Because of floating point overflow,\n",
       "    this rule may result in the last element of `out` being greater\n",
       "    than `stop`.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "numpy.linspace : Evenly spaced numbers with careful handling of endpoints.\n",
       "numpy.ogrid: Arrays of evenly spaced numbers in N-dimensions.\n",
       "numpy.mgrid: Grid-shaped arrays of evenly spaced numbers in N-dimensions.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> np.arange(3)\n",
       "array([0, 1, 2])\n",
       ">>> np.arange(3.0)\n",
       "array([ 0.,  1.,  2.])\n",
       ">>> np.arange(3,7)\n",
       "array([3, 4, 5, 6])\n",
       ">>> np.arange(3,7,2)\n",
       "array([3, 5])\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?np.arange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to import only specified columns from a csv file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv',usecols=['crim','medv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim  medv\n",
      "0  0.00632  24.0\n",
      "1  0.02731  21.6\n",
      "2  0.02729  34.7\n",
      "3  0.03237  33.4\n",
      "4  0.06905  36.2\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get the nrows, ncolumns, datatype, summary stats of each column of a dataframe? Also get the array and list equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 27)\n"
     ]
    }
   ],
   "source": [
    "# num rows/cols\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manufacturer       object\n",
      "Model              object\n",
      "Type               object\n",
      "Min.Price         float64\n",
      "Price             float64\n",
      "                   ...   \n",
      "Rear.seat.room    float64\n",
      "Luggage.room      float64\n",
      "Weight            float64\n",
      "Origin             object\n",
      "Make               object\n",
      "Length: 27, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# datatypes\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64    18\n",
      "object      9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# how many cols of each dtype\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Min.Price      Price  Max.Price   MPG.city  MPG.highway  ...  \\\n",
      "count  86.000000  91.000000  88.000000  84.000000    91.000000  ...   \n",
      "mean   17.118605  19.616484  21.459091  22.404762    29.065934  ...   \n",
      "std     8.828290   9.724280  10.696563   5.841520     5.370293  ...   \n",
      "min     6.700000   7.400000   7.900000  15.000000    20.000000  ...   \n",
      "25%    10.825000  12.350000  14.575000  18.000000    26.000000  ...   \n",
      "50%    14.600000  17.700000  19.150000  21.000000    28.000000  ...   \n",
      "75%    20.250000  23.500000  24.825000  25.000000    31.000000  ...   \n",
      "max    45.400000  61.900000  80.000000  46.000000    50.000000  ...   \n",
      "\n",
      "           Width  Turn.circle  Rear.seat.room  Luggage.room       Weight  \n",
      "count  87.000000    88.000000       89.000000     74.000000    86.000000  \n",
      "mean   69.448276    38.954545       27.853933     13.986486  3104.593023  \n",
      "std     3.778023     3.304157        3.018129      3.120824   600.129993  \n",
      "min    60.000000    32.000000       19.000000      6.000000  1695.000000  \n",
      "25%    67.000000    36.000000       26.000000     12.000000  2647.500000  \n",
      "50%    69.000000    39.000000       27.500000     14.000000  3085.000000  \n",
      "75%    72.000000    42.000000       30.000000     16.000000  3567.500000  \n",
      "max    78.000000    45.000000       36.000000     22.000000  4105.000000  \n",
      "\n",
      "[8 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "df_stats = df.describe()\n",
    "print(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Acura' 'Integra' 'Small' ... 2705.0 'non-USA' 'Acura Integra']\n",
      " [nan 'Legend' 'Midsize' ... 3560.0 'non-USA' 'Acura Legend']\n",
      " ['Audi' '90' 'Compact' ... 3375.0 'non-USA' 'Audi 90']\n",
      " ...\n",
      " ['Volkswagen' 'Corrado' 'Sporty' ... 2810.0 'non-USA'\n",
      "  'Volkswagen Corrado']\n",
      " ['Volvo' '240' 'Compact' ... 2985.0 'non-USA' 'Volvo 240']\n",
      " [nan '850' 'Midsize' ... 3245.0 'non-USA' 'Volvo 850']]\n"
     ]
    }
   ],
   "source": [
    "df_arr = df.values\n",
    "print(df_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Acura', 'Integra', 'Small', 12.9, 15.9, 18.8, 25.0, 31.0, 'None', 'Front', '4', 1.8, 140.0, 6300.0, 2890.0, 'Yes', 13.2, 5.0, 177.0, 102.0, 68.0, 37.0, 26.5, nan, 2705.0, 'non-USA', 'Acura Integra'], [nan, 'Legend', 'Midsize', 29.2, 33.9, 38.7, 18.0, 25.0, 'Driver & Passenger', 'Front', '6', 3.2, 200.0, 5500.0, 2335.0, 'Yes', 18.0, 5.0, 195.0, 115.0, 71.0, 38.0, 30.0, 15.0, 3560.0, 'non-USA', 'Acura Legend'], ['Audi', '90', 'Compact', 25.9, 29.1, 32.3, 20.0, 26.0, 'Driver only', 'Front', '6', 2.8, 172.0, 5500.0, 2280.0, 'Yes', 16.9, 5.0, 180.0, 102.0, 67.0, 37.0, 28.0, 14.0, 3375.0, 'non-USA', 'Audi 90'], ['Audi', '100', 'Midsize', nan, 37.7, 44.6, 19.0, 26.0, 'Driver & Passenger', nan, '6', nan, 172.0, 5500.0, 2535.0, nan, 21.1, 6.0, 193.0, 106.0, nan, 37.0, 31.0, 17.0, 3405.0, 'non-USA', 'Audi 100'], ['BMW', '535i', 'Midsize', nan, 30.0, nan, 22.0, 30.0, nan, 'Rear', '4', 3.5, 208.0, 5700.0, 2545.0, 'Yes', 21.1, 4.0, 186.0, 109.0, 69.0, 39.0, 27.0, 13.0, 3640.0, 'non-USA', 'BMW 535i']]\n"
     ]
    }
   ],
   "source": [
    "#list\n",
    "df_list = df.values.tolist()\n",
    "print(df_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to extract the row and column number of a particular cell with given criterion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>300E</td>\n",
       "      <td>Midsize</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Manufacturer Model     Type\n",
       "58  Mercedes-Benz  300E  Midsize"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manuf with highest price\n",
    "df.loc[df.Price==np.max(df.Price),['Manufacturer','Model','Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.9"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df.Price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to rename a specific columns in a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Manufacturer', 'Model', 'Type', 'Min.Price', 'Price', 'Max.Price',\n",
      "       'MPG.city', 'MPG.highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
      "       'EngineSize', 'Horsepower', 'RPM', 'Rev.per.mile', 'Man.trans.avail',\n",
      "       'Fuel.tank.capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
      "       'Turn.circle', 'Rear.seat.room', 'Luggage.room', 'Weight', 'Origin',\n",
      "       'Make'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns= {'Type':'CarType\"'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to check if a dataframe has any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to count the number of missing values in each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min.Price</th>\n",
       "      <th>Max.Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.9</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.2</td>\n",
       "      <td>38.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.9</td>\n",
       "      <td>32.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Min.Price  Max.Price\n",
       "0       12.9       18.8\n",
       "1       29.2       38.7\n",
       "2       25.9       32.3\n",
       "3        NaN       44.6\n",
       "4        NaN        NaN"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Min.Price','Max.Price']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Min.Price  Max.Price\n",
      "0  12.900000  18.800000\n",
      "1  29.200000  38.700000\n",
      "2  25.900000  32.300000\n",
      "3  17.118605  44.600000\n",
      "4  17.118605  21.459091\n"
     ]
    }
   ],
   "source": [
    "df_out = df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x: x.fillna(x.mean()))\n",
    "print(df_out.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to replace missing values of multiple numeric columns with the mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Min.Price  Max.Price\n",
      "0  12.900000  18.800000\n",
      "1  29.200000  38.700000\n",
      "2  25.900000  32.300000\n",
      "3  17.118605  44.600000\n",
      "4  17.118605  21.459091\n"
     ]
    }
   ],
   "source": [
    "df_out = df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x: x.fillna(x.mean()))\n",
    "print(df_out.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use apply function on existing columns with global variables as additional arguments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min.Price</th>\n",
       "      <th>Max.Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.9</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.2</td>\n",
       "      <td>38.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.9</td>\n",
       "      <td>32.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Min.Price  Max.Price\n",
       "0       12.9       18.8\n",
       "1       29.2       38.7\n",
       "2       25.9       32.3\n",
       "3        NaN       44.6\n",
       "4        NaN        NaN"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "df[['Min.Price','Max.Price']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Min.Price': np.nanmean, 'Max.Price': np.nanmedian}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min.Price</th>\n",
       "      <th>Max.Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.900000</td>\n",
       "      <td>18.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.200000</td>\n",
       "      <td>38.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.900000</td>\n",
       "      <td>32.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.118605</td>\n",
       "      <td>44.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.118605</td>\n",
       "      <td>19.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Min.Price  Max.Price\n",
       "0  12.900000      18.80\n",
       "1  29.200000      38.70\n",
       "2  25.900000      32.30\n",
       "3  17.118605      44.60\n",
       "4  17.118605      19.15"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Min.Price','Max.Price']] = df[['Min.Price','Max.Price']].apply(lambda x, d: x.fillna(d[x.name](x)),args=(d,))\n",
    "df[['Min.Price','Max.Price']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    (a, a)\n",
      "1    (b, b)\n",
      "2    (c, c)\n",
      "3    (d, d)\n",
      "4    (e, e)\n",
      "5    (a, a)\n",
      "6    (b, b)\n",
      "7    (c, c)\n",
      "8    (d, d)\n",
      "9    (e, e)\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a':range(100,110), 'b':range(200, 210)})\n",
    "\n",
    "def modulo(x, n=5):\n",
    "    return x%n\n",
    "\n",
    "some_dict = {0: 'a', 1:'b', 2:'c', 3:'d', 4:'e'}\n",
    "print(df.apply(lambda row,n, map_dict: (map_dict[modulo(row['a'],n)], map_dict[modulo(row['b'],n)]), axis=1, args=(5, some_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to select a specific column from a dataframe as a dataframe instead of a series? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[['a']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.loc[:,['a']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to change the order of columns of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c   d   e\n",
       "0   0   1   2   3   4\n",
       "1   5   6   7   8   9\n",
       "2  10  11  12  13  14\n",
       "3  15  16  17  18  19"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>b</th>\n",
       "      <th>a</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    c   b   a   d   e\n",
       "0   2   1   0   3   4\n",
       "1   7   6   5   8   9\n",
       "2  12  11  10  13  14\n",
       "3  17  16  15  18  19"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[list('cbade')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>b</th>\n",
       "      <th>a</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    c   b   a   d   e\n",
       "0   2   1   0   3   4\n",
       "1   7   6   5   8   9\n",
       "2  12  11  10  13  14\n",
       "3  17  16  15  18  19"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['c','b','a','d','e']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_columns(df, col1=None, col2=None):\n",
    "    colnames = df.columns.tolist()\n",
    "    i1, i2 = colnames.index(col1), colnames.index(col2)\n",
    "    colnames[i2], colnames[i1] = colnames[i1], colnames[i2]\n",
    "    return df[colnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = switch_columns(df, 'a', 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to set the number of rows and columns displayed in the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.describe_option().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to format or suppress scientific notations in a pandas dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.random(4)**10, columns=['random'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.036547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.245715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     random\n",
       "0  0.036547\n",
       "1  0.000015\n",
       "2  0.003437\n",
       "3  0.245715"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   random\n",
       "0  0.0365\n",
       "1  0.0000\n",
       "2  0.0034\n",
       "3  0.2457"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   random\n",
       "0  0.0365\n",
       "1  0.0000\n",
       "2  0.0034\n",
       "3  0.2457"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(lambda x: round(x,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0365\n",
       "1    0.0000\n",
       "2    0.0034\n",
       "3    0.2457\n",
       "dtype: object"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(lambda x: '%.4f' % x, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to format all the values in a dataframe as percentages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.random(4), columns=['random'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_5346de7e_a924_11ea_8fb0_cc2f71a90848\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >random</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_5346de7e_a924_11ea_8fb0_cc2f71a90848level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_5346de7e_a924_11ea_8fb0_cc2f71a90848row0_col0\" class=\"data row0 col0\" >73.118%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5346de7e_a924_11ea_8fb0_cc2f71a90848level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_5346de7e_a924_11ea_8fb0_cc2f71a90848row1_col0\" class=\"data row1 col0\" >85.919%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5346de7e_a924_11ea_8fb0_cc2f71a90848level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_5346de7e_a924_11ea_8fb0_cc2f71a90848row2_col0\" class=\"data row2 col0\" >60.109%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5346de7e_a924_11ea_8fb0_cc2f71a90848level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_5346de7e_a924_11ea_8fb0_cc2f71a90848row3_col0\" class=\"data row3 col0\" >88.382%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x175724e4108>"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = df.style.format({\n",
    "    'random':'{0:0.3%}'.format,\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to filter every nth row in a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Manufacturer    Model     Type\n",
      "0         Acura  Integra    Small\n",
      "20     Chrysler  LeBaron  Compact\n",
      "40        Honda  Prelude   Sporty\n",
      "60      Mercury   Cougar  Midsize\n",
      "80       Subaru   Loyale    Small\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[::20, :][['Manufacturer', 'Model', 'Type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create a primary key index by combining relevant columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0,1,2,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Manufacturer','Model','Type']] = df[['Manufacturer','Model','Type']].fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df.Manufacturer + \"_\" + df.Model + \"_\" + df.Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(df.index.is_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get the row number of the nth largest value in a column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "df['a'].argsort()[::-1][n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to find the position of the nth largest value greater than a given value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.randint(1, 100, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ser:  [71, 13, 90, 60, 44, 98, 88, 10, 66, 12, 68, 2, 38, 77, 52] mean:  53\n"
     ]
    }
   ],
   "source": [
    "print('ser: ', ser.tolist(), 'mean: ', round(ser.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     98\n",
       "2     90\n",
       "6     88\n",
       "13    77\n",
       "0     71\n",
       "10    68\n",
       "8     66\n",
       "3     60\n",
       "dtype: int32"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser[ser > ser.mean()].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get the last n rows of a dataframe with row sum > 100?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3\n",
       "0  30  36  27  37\n",
       "1  15  37  29  28\n",
       "2  14  25  21  35\n",
       "3  13  28  34  27\n",
       "4  25  24  14  37"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowsums = df.apply(np.sum,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  1,  3,  6,  7,  9, 10, 12, 14], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "print(np.where(rowsums > 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1   2   3\n",
      "12  24  26  32  26\n",
      "14  34  20  36  22\n"
     ]
    }
   ],
   "source": [
    "last_two_rows = df.iloc[np.where(rowsums > 100)[0][-2:],:]\n",
    "print(last_two_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  How to find and cap outliers from a series or dataframe column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.logspace(-2, 2, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_outliers(ser, low_perc, high_perc):\n",
    "    low, high = ser.quantile([low_perc,high_perc])\n",
    "    print(low_perc, '%ile', low, '|', high_perc, '%ile' , high)\n",
    "    ser[ser<low] = low\n",
    "    ser[ser>high] = high\n",
    "    return(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 %ile 0.016049294076965887 | 0.95 %ile 63.876672220183934\n"
     ]
    }
   ],
   "source": [
    "capped_ser = cap_outliers(ser,0.05,0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to reshape a dataframe to the largest possible square after removing the negative values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: remove negative values from arr\n",
    "arr = df[df > 0].values.flatten()\n",
    "arr_qualified = arr[~np.isnan(arr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: find side-length of largest possible square\n",
    "n = int(np.floor(arr_qualified.shape[0]**.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9. 13. 16. 22. 21. 45. 12.  6.]\n",
      " [29. 13. 27. 37. 41. 37. 47. 26.]\n",
      " [17. 11. 48. 29. 34. 31. 49. 47.]\n",
      " [25.  7.  6. 14. 22. 27. 14. 39.]\n",
      " [ 8. 37. 25. 18.  2. 10. 18.  9.]\n",
      " [21. 34. 10. 11.  2. 47. 15. 40.]\n",
      " [48. 36. 27.  7. 43. 20.  8. 19.]\n",
      " [21. 15. 44.  6. 19. 33. 35. 27.]]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Take top n^2 items without changing positions\n",
    "top_indexes = np.argsort(arr_qualified)[::-1]\n",
    "output = np.take(arr_qualified, sorted(top_indexes[:n**2])).reshape(n, -1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9., 13., 16., 22., 21., 45., 12.,  6., 29.,  1.])"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_qualified[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24, 51, 20, 25, 15, 48,  5, 61, 55, 13], dtype=int64)"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_indexes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Return a new list containing all items from the iterable in ascending order.\n",
       "\n",
       "A custom key function can be supplied to customize the sort order, and the\n",
       "reverse flag can be set to request the result in descending order.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to swap two rows of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4\n",
      "0   0   1   2   3   4\n",
      "1   5   6   7   8   9\n",
      "2  10  11  12  13  14\n",
      "3  15  16  17  18  19\n",
      "4  20  21  22  23  24\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap(df_input , row1, row2):\n",
    "    a , b = df_input.iloc[row1,:].copy(), df_input.iloc[row2,:].copy()\n",
    "    df_input.iloc[row1,:] = b\n",
    "    df_input.iloc[row2,:] = a\n",
    "    return df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4\n",
      "0   5   6   7   8   9\n",
      "1   0   1   2   3   4\n",
      "2  10  11  12  13  14\n",
      "3  15  16  17  18  19\n",
      "4  20  21  22  23  24\n"
     ]
    }
   ],
   "source": [
    "df_swapped = swap(df,0,1)\n",
    "print(df_swapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to reverse the rows of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4\n",
      "0   0   1   2   3   4\n",
      "1   5   6   7   8   9\n",
      "2  10  11  12  13  14\n",
      "3  15  16  17  18  19\n",
      "4  20  21  22  23  24\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_row(df_input , col1, col2):\n",
    "    a , b = df_input.iloc[:,col1].copy(), df_input.iloc[:,col2].copy()\n",
    "    df_input.iloc[:,col1] = b\n",
    "    df_input.iloc[:,col2] = a\n",
    "    return df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4\n",
      "0   1   0   2   3   4\n",
      "1   6   5   7   8   9\n",
      "2  11  10  12  13  14\n",
      "3  16  15  17  18  19\n",
      "4  21  20  22  23  24\n"
     ]
    }
   ],
   "source": [
    "df_swapped = swap_row(df,0,1)\n",
    "print(df_swapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create one-hot encodings of a categorical variable (dummy variables)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   d   e\n",
      "0   0   1   2   3   4\n",
      "1   5   6   7   8   9\n",
      "2  10  11  12  13  14\n",
      "3  15  16  17  18  19\n",
      "4  20  21  22  23  24\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5,-1), columns=list('abcde'))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  5  10  15  20   b   c   d   e\n",
      "0  1  0   0   0   0   1   2   3   4\n",
      "1  0  1   0   0   0   6   7   8   9\n",
      "2  0  0   1   0   0  11  12  13  14\n",
      "3  0  0   0   1   0  16  17  18  19\n",
      "4  0  0   0   0   1  21  22  23  24\n"
     ]
    }
   ],
   "source": [
    "df_onehot = pd.concat([pd.get_dummies(df['a']),df[list('bcde')]],axis=1)\n",
    "print(df_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which column contains the highest number of row-wise maximum values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>54</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "      <td>66</td>\n",
       "      <td>77</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>53</td>\n",
       "      <td>71</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3\n",
       "0  17  22  54  75\n",
       "1  86  66  77  39\n",
       "2  29  53  71  27\n",
       "3  22  40  98   4\n",
       "4  37  47  16  48"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col with max:  3\n"
     ]
    }
   ],
   "source": [
    "print('Col with max: ', df.apply(np.argmax,axis=1).value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    0\n",
       "2    2\n",
       "3    2\n",
       "4    3\n",
       "5    3\n",
       "6    0\n",
       "7    3\n",
       "8    1\n",
       "9    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(np.argmax,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create a new column that contains the row number of nearest column by euclidean distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    p   q   r   s\n",
      "a  72  40  42  97\n",
      "b  66  68  92   7\n",
      "c   6   6  48  20\n",
      "d  10  64   9  56\n",
      "e  79  69  89  30\n",
      "f  16  46  11  95\n",
      "g  98  55  56   3\n",
      "h  34  14  94  23\n",
      "i  58  16  66   5\n",
      "j  13  62  26  94\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init outputs\n",
    "nearest_rows = []\n",
    "nearest_distance = []\n",
    "for i, row in df.iterrows():\n",
    "    curr = row\n",
    "    rest = df.drop(i)\n",
    "    e_dists = {} # init dict to store euclidean dist\n",
    "    # iterate\n",
    "    for j , contestant in rest.iterrows():\n",
    "        # compute dist\n",
    "        e_dists.update({j: round(np.linalg.norm(curr.values - contestant.values))})\n",
    "    # update nearest row\n",
    "    nearest_rows.append(min(e_dists,key=e_dists.get)) # \n",
    "    nearest_distance.append(min(e_dists.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  dist\n",
      "a  f  64.0\n",
      "b  e  27.0\n",
      "c  h  55.0\n",
      "d  j  42.0\n",
      "e  b  27.0\n",
      "f  j  22.0\n",
      "g  e  49.0\n",
      "h  i  41.0\n",
      "i  h  41.0\n",
      "j  f  22.0\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(nearest_rows)\n",
    "results['dist'] = nearest_distance\n",
    "results.index = df.index\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>nearest_row</th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>77</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>j</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>62</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>56</td>\n",
       "      <td>j</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>15</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>92</td>\n",
       "      <td>j</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>46</td>\n",
       "      <td>75</td>\n",
       "      <td>58</td>\n",
       "      <td>84</td>\n",
       "      <td>j</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>61</td>\n",
       "      <td>15</td>\n",
       "      <td>j</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "      <td>86</td>\n",
       "      <td>j</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>49</td>\n",
       "      <td>17</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>j</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>24</td>\n",
       "      <td>79</td>\n",
       "      <td>j</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>37</td>\n",
       "      <td>75</td>\n",
       "      <td>14</td>\n",
       "      <td>64</td>\n",
       "      <td>j</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>j</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>i</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p   q   r   s nearest_row   dist\n",
       "a  77  26  56  60           j  101.0\n",
       "b  62  83  84  56           j  128.0\n",
       "c  15  47  14  92           j   98.0\n",
       "d  46  75  58  84           j  120.0\n",
       "e  39  21  61  15           j   97.0\n",
       "f  41  45  74  86           j  118.0\n",
       "g  49  17  45  42           j   79.0\n",
       "h  43  43  24  79           j   89.0\n",
       "i  37  75  14  64           j   90.0\n",
       "j  15  15   2   2           i  128.0"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to know the maximum possible correlation value of each column against other columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
